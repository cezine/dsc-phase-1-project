{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "## Step 1: Importing the data\n",
    "\n",
    "Our data are contained in the zippedData directory of this repo and will need to be unzipped and imported to be useful for this analysis. First we will import the required packages and build an unzip function to help access our relevant files.\n",
    "\n",
    "### How did we choose our data?\n",
    "\n",
    "We decided to use data from `tn.movie_budgets.csv.gz`, `imdb.title.basics.csv.gz` and `imdb.name.basics.csv.gz`. We chose `tn.movie_budgets.csv.gz` because it provided more detailed information about revenue and production costs which allowed us to ask and answer more meaningful questions about the overall return on investment for each film. We also included `imdb.title.basics.csv.gz` in order to take a more detailed look at what _types_ of films performed best over time. Finally, we took a look at the personell files in `imdb.name.basics.csv.gz` to answer questions about which indusdry professionals were involved in successful titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import gzip\n",
    "from io import StringIO\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# This function uses try statements to push through errors and unzip the csv data\n",
    "def unzip_csv(file_location): \n",
    "    file = gzip.open(file_location, 'rb')\n",
    "    content = file.read()\n",
    "    file.close()\n",
    "    try:\n",
    "        content_str = str(content,'utf-8')\n",
    "        content_data = StringIO(content_str) \n",
    "    except:\n",
    "        content_str = str(content,'latin-1')\n",
    "        content_data = StringIO(content_str) \n",
    "    try:\n",
    "        return pd.read_csv(content_data)\n",
    "    except:\n",
    "        return pd.read_csv(content_data, sep='\\t')\n",
    "\n",
    "    \n",
    "#hard-coding the file-locations and nicknames into a dict for future reference\n",
    "file_locations = ['zippedData/imdb.name.basics.csv.gz'\n",
    "                  ,'zippedData/imdb.title.basics.csv.gz'\n",
    "                  ,'zippedData/tn.movie_budgets.csv.gz']\n",
    "\n",
    "file_nicknames = ['name','basics','budgets']\n",
    "\n",
    "\n",
    "#this dicitonary comprehension uses a zip function to smush the two lists together and then parse them into a dict\n",
    "#we also have a reference for each raw df and its location on the drive.\n",
    "file_dict = {k:v for k,v in zip(file_nicknames,file_locations)}\n",
    "\n",
    "#we unzip and define frames\n",
    "name_raw = unzip_csv(file_dict['name'])\n",
    "basics_raw = unzip_csv(file_dict['basics'])\n",
    "budgets_raw = unzip_csv(file_dict['budgets'])\n",
    "\n",
    "#renaming frames for cleaning\n",
    "name = name_raw\n",
    "basics = basics_raw\n",
    "budgets = budgets_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Cleaning the Data\n",
    "\n",
    "In the next step we take the raw data frames and format the values to their appropriate data types, drop duplicates, null values, and redundant or irrelevant columns. We'll examine the head of our budgets DataFrame below as a starting off point:\n",
    "\n",
    "### Budgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "budgets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budgets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budgets.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at some summary data for the budgets data frame we can see that the we have a few tasks before this is going to be useful for analysis. There seems to be a redundant index column, and the numerical and time information is in the wrong format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#id column is a redundant index so we're dropping it\n",
    "budgets.drop('id', axis=1, inplace=True)\n",
    "\n",
    "#setting date column to datatime object for use in charts etc.\n",
    "budgets['release_date'] = pd.to_datetime(budgets['release_date'])\n",
    "\n",
    "#stripping any unseen or unknown whitespace from the object locales\n",
    "budgets.columns.str.strip()\n",
    "budgets['movie'] = budgets['movie'].str.strip()\n",
    "\n",
    "#this function launders the money ;D\n",
    "def clean_money(budgets_series):\n",
    "    #the map function applys the .replace to each cell in the given series, x[1:] skips the $\n",
    "    return budgets_series.map(lambda x: int(x[1:].replace(',','')))\n",
    "\n",
    "budgets['production_budget'] = clean_money(budgets['production_budget'])\n",
    "budgets['domestic_gross'] = clean_money(budgets['domestic_gross'])\n",
    "budgets['worldwide_gross'] = clean_money(budgets['worldwide_gross'])\n",
    "\n",
    "#adding in relevant columns\n",
    "budgets['foreign_gross'] = budgets.worldwide_gross - budgets.domestic_gross\n",
    "budgets['profit'] = budgets.worldwide_gross - budgets.production_budget\n",
    "\n",
    "#dropping duplicates\n",
    "budgets.drop_duplicates('movie', keep='first',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good now\n",
    "budgets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics\n",
    "Now the general shape of the cleaning process has been defined we can rinse and repeat on our other data sets, making them easier to use in later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basics.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basics.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Null values\n",
    "So it looks like the column we're most interest in from this data frame has a rather signifigant portion of null values, something we didnt encounter in the other data frame we already processed. Let's address the null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the dataframe below proivdes a list of indices that contain a null value in the genre column the genre column is very \n",
    "#important to our analysis so we'll drop null values.\n",
    "to_drop = basics[basics['genres'].isna()==True].index\n",
    "\n",
    "#simple drop will finish the job\n",
    "basics.drop(to_drop,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pressing on...\n",
    "\n",
    "Now that the null values have been removed we will run a similar set of cleaning techniques on the dataframe as we did previously. Since the 'movie' column in budgets is how we're going to identify which records go where we are going to adjust the primary title column of basics in order to more easily denote the implied relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basics['movie'] = basics['primary_title']\n",
    "\n",
    "#keeping only 'movie' and 'ttconst' as keys for our other data, and 'genres' for further analysis\n",
    "basics.drop(['primary_title','original_title','start_year'\n",
    "                ,'runtime_minutes'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns look correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basics.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the strip functions remove unwanted whitespace if its lurking in there\n",
    "basics.columns = basics.columns.str.strip()\n",
    "\n",
    "for column in list(basics.columns):\n",
    "    basics[column] = basics[column].str.strip()\n",
    "\n",
    "#Dropping duplicates\n",
    "basics.drop_duplicates('movie', keep='first', inplace=True)\n",
    "    \n",
    "#this .map will apply a .split to all the genres at each \",\" decoding the genres data into a nested list.\n",
    "basics['genres'] = basics['genres'].map(lambda x: x.split(\",\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As demonstrated below the previously difficult to use string data has now been munged into a useful format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basics['genres'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basics['genres'][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping these since they're outside the scope of our analysis\n",
    "name.drop(['nconst','birth_year','death_year',],axis=1,inplace=True)\n",
    "\n",
    "#this phrase finds null values in either column\n",
    "to_drop = name[(name['primary_profession'].isna()==True)|\n",
    "               name['known_for_titles'].isna()==True].index\n",
    "\n",
    "name.drop(to_drop,inplace=True)\n",
    "\n",
    "#cleaning the object data\n",
    "name.columns = name.columns.str.strip()\n",
    "\n",
    "#for loop will work here since all columns are object data\n",
    "for column in list(name.columns):\n",
    "    name[column] = name[column].str.strip()\n",
    "\n",
    "#splitting the cleaned data into nested lists\n",
    "name['known_for_titles'] = name['known_for_titles'].map(lambda x: x.split(\",\"))\n",
    "name['primary_profession'] = name['primary_profession'].map(lambda x: x.split(\",\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unnesting the tconst values\n",
    "Now our primary linkage to the rest of our data set seems to be encoded in a nested list. To access these records we need to employe .explode() to get just 1 tconst and job value per record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_exploded = name.explode('known_for_titles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_exploded = name_exploded.explode('primary_profession', ignore_index=True)\n",
    "name_exploded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_exploded.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_exploded = name_exploded[(name_exploded['primary_profession']=='director')| (name_exploded['primary_profession']=='producer')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_exploded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_gb = name_exploded.groupby('known_for_titles')\n",
    "group_dict = name_gb.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_gb = name_exploded.groupby(['known_for_titles'])['primary_name'].apply(', '.join).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_gb2 = name_exploded.groupby(['known_for_titles'])['primary_profession'].apply(', '.join).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = name_gb.merge(name_gb2)\n",
    "name['primary_profession'] = name['primary_profession'].map(lambda x: x.split(\",\"))\n",
    "name['primary_name'] = name['primary_name'].map(lambda x: x.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = budgets.merge(basics.merge(name,how='left',left_on='tconst',right_on='known_for_titles'),how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['tconst','known_for_titles'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
